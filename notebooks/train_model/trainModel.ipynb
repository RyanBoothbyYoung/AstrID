{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f51c6a31-0548-4f9f-b1ca-2652f2caadde",
   "metadata": {},
   "source": [
    "## UnSu Unet Object Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d8c9b41-da1a-431e-8133-f228618ec132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.initializers import he_uniform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d260a505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b110441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom functions to extract our Image arrays and Pixel Mask arrays from our created fits files dataset\n",
    "from dataGathering import extractImageArray, extractPixelMaskArray, extract_star_catalog, getStarData, getImagePlot, getPixelMaskPlot, displayImagePlot, displayPixelMaskPlot\n",
    "\n",
    "# Import astropy to read fits files, and os to interact with the file system\n",
    "from astropy.io import fits\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b75e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getStarData('II/246', 150, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0ad1a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data0.fits added to dataset\n",
      "data1.fits added to dataset\n",
      "data10.fits added to dataset\n",
      "data100.fits added to dataset\n",
      "data101.fits added to dataset\n",
      "data102.fits added to dataset\n",
      "data103.fits added to dataset\n",
      "data104.fits added to dataset\n",
      "data105.fits added to dataset\n",
      "data106.fits added to dataset\n",
      "data107.fits added to dataset\n",
      "data108.fits added to dataset\n",
      "data109.fits added to dataset\n",
      "data11.fits added to dataset\n",
      "data110.fits added to dataset\n",
      "data111.fits added to dataset\n",
      "data112.fits added to dataset\n",
      "data113.fits added to dataset\n",
      "data114.fits added to dataset\n",
      "data115.fits added to dataset\n",
      "data116.fits added to dataset\n",
      "data117.fits added to dataset\n",
      "data118.fits added to dataset\n",
      "data119.fits added to dataset\n",
      "data12.fits added to dataset\n",
      "data120.fits added to dataset\n",
      "data121.fits added to dataset\n",
      "data122.fits added to dataset\n",
      "data123.fits added to dataset\n",
      "data124.fits added to dataset\n",
      "data125.fits added to dataset\n",
      "data126.fits added to dataset\n",
      "data127.fits added to dataset\n",
      "data128.fits added to dataset\n",
      "data129.fits added to dataset\n",
      "data13.fits added to dataset\n",
      "data130.fits added to dataset\n",
      "data131.fits added to dataset\n",
      "data132.fits added to dataset\n",
      "data133.fits added to dataset\n",
      "data134.fits added to dataset\n",
      "data135.fits added to dataset\n",
      "data136.fits added to dataset\n",
      "data137.fits added to dataset\n",
      "data138.fits added to dataset\n",
      "data139.fits added to dataset\n",
      "data14.fits added to dataset\n",
      "data140.fits added to dataset\n",
      "data141.fits added to dataset\n",
      "data142.fits added to dataset\n",
      "data143.fits added to dataset\n",
      "data144.fits added to dataset\n",
      "data145.fits added to dataset\n",
      "data146.fits added to dataset\n",
      "data147.fits added to dataset\n",
      "data148.fits added to dataset\n",
      "data149.fits added to dataset\n",
      "data15.fits added to dataset\n",
      "data16.fits added to dataset\n",
      "data17.fits added to dataset\n",
      "data18.fits added to dataset\n",
      "data19.fits added to dataset\n",
      "data2.fits added to dataset\n",
      "data20.fits added to dataset\n",
      "data21.fits added to dataset\n",
      "data22.fits added to dataset\n",
      "data23.fits added to dataset\n",
      "data24.fits added to dataset\n",
      "data25.fits added to dataset\n",
      "data26.fits added to dataset\n",
      "data27.fits added to dataset\n",
      "data28.fits added to dataset\n",
      "data29.fits added to dataset\n",
      "data3.fits added to dataset\n",
      "data30.fits added to dataset\n",
      "data31.fits added to dataset\n",
      "data32.fits added to dataset\n",
      "data33.fits added to dataset\n",
      "data34.fits added to dataset\n",
      "data35.fits added to dataset\n",
      "data36.fits added to dataset\n",
      "data37.fits added to dataset\n",
      "data38.fits added to dataset\n",
      "data39.fits added to dataset\n",
      "data4.fits added to dataset\n",
      "data40.fits added to dataset\n",
      "data41.fits added to dataset\n",
      "data42.fits added to dataset\n",
      "data43.fits added to dataset\n",
      "data44.fits added to dataset\n",
      "data45.fits added to dataset\n",
      "data46.fits added to dataset\n",
      "data47.fits added to dataset\n",
      "data48.fits added to dataset\n",
      "data49.fits added to dataset\n",
      "data5.fits added to dataset\n",
      "data50.fits added to dataset\n",
      "data51.fits added to dataset\n",
      "data52.fits added to dataset\n",
      "data53.fits added to dataset\n",
      "data54.fits added to dataset\n",
      "data55.fits added to dataset\n",
      "data56.fits added to dataset\n",
      "data57.fits added to dataset\n",
      "data58.fits added to dataset\n",
      "data59.fits added to dataset\n",
      "data6.fits added to dataset\n",
      "data60.fits added to dataset\n",
      "data61.fits added to dataset\n",
      "data62.fits added to dataset\n",
      "data63.fits added to dataset\n",
      "data64.fits added to dataset\n",
      "data65.fits added to dataset\n",
      "data66.fits added to dataset\n",
      "data67.fits added to dataset\n",
      "data68.fits added to dataset\n",
      "data69.fits added to dataset\n",
      "data7.fits added to dataset\n",
      "data70.fits added to dataset\n",
      "data71.fits added to dataset\n",
      "data72.fits added to dataset\n",
      "data73.fits added to dataset\n",
      "data74.fits added to dataset\n",
      "data75.fits added to dataset\n",
      "data76.fits added to dataset\n",
      "data77.fits added to dataset\n",
      "data78.fits added to dataset\n",
      "data79.fits added to dataset\n",
      "data8.fits added to dataset\n",
      "data80.fits added to dataset\n",
      "data81.fits added to dataset\n",
      "data82.fits added to dataset\n",
      "data83.fits added to dataset\n",
      "data84.fits added to dataset\n",
      "data85.fits added to dataset\n",
      "data86.fits added to dataset\n",
      "data87.fits added to dataset\n",
      "data88.fits added to dataset\n",
      "data89.fits added to dataset\n",
      "data9.fits added to dataset\n",
      "data90.fits added to dataset\n",
      "data91.fits added to dataset\n",
      "data92.fits added to dataset\n",
      "data93.fits added to dataset\n",
      "data94.fits added to dataset\n",
      "data95.fits added to dataset\n",
      "data96.fits added to dataset\n",
      "data97.fits added to dataset\n",
      "data98.fits added to dataset\n",
      "data99.fits added to dataset\n"
     ]
    }
   ],
   "source": [
    "# Create images and masks arrays lists\n",
    "images = []\n",
    "masks = []\n",
    "\n",
    "# Create df to store the star data inside each fits file\n",
    "star_data = []\n",
    "\n",
    "# Create a list of all the fits files in the dataset folder\n",
    "fits_files = os.listdir('data/')\n",
    "\n",
    "# For all the fits files in the dataset folder specified in file_path, extract the image and mask arrays to the respective lists\n",
    "file_path = 'data/'\n",
    "for file in os.listdir(file_path):\n",
    "    if file.endswith('.fits'):\n",
    "        images.append(extractImageArray(file_path + file))\n",
    "        masks.append(extractPixelMaskArray(file_path + file))\n",
    "        star_data.append(extract_star_catalog(file_path + file))\n",
    "\n",
    "        print(file + ' added to dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60dab5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c32043a-b07f-4121-abd4-45bbdd2db5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder path\n",
    "    #32 kernels\n",
    "    #3x3 kernel size\n",
    "    #padding = same considers edges in the input\n",
    "# Example function to create a U-Net model\n",
    "def unet_model(input_shape, filters, kernel_size, activation, padding, initializer):\n",
    "    inputs = layers.Input(input_shape)\n",
    "\n",
    "    # Encoder path\n",
    "    c1 = layers.Conv2D(filters[0], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(inputs)\n",
    "    c1 = layers.Conv2D(filters[0], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(filters[1], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(p1)\n",
    "    c2 = layers.Conv2D(filters[1], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(filters[2], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(p2)\n",
    "    c3 = layers.Conv2D(filters[2], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(c3)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = layers.Conv2D(filters[3], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(p3)\n",
    "    c4 = layers.Conv2D(filters[3], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(c4)\n",
    "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = layers.Conv2D(filters[4], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(p4)\n",
    "    c5 = layers.Conv2D(filters[4], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(c5)\n",
    "\n",
    "    # Decoder path\n",
    "    u6 = layers.Conv2DTranspose(filters[3], (2, 2), strides=(2, 2), padding=padding)(c5)\n",
    "    u6 = layers.concatenate([u6, c4])\n",
    "    c6 = layers.Conv2D(filters[3], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(u6)\n",
    "    c6 = layers.Conv2D(filters[3], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(c6)\n",
    "\n",
    "    u7 = layers.Conv2DTranspose(filters[2], (2, 2), strides=(2, 2), padding=padding)(c6)\n",
    "    u7 = layers.concatenate([u7, c3])\n",
    "    c7 = layers.Conv2D(filters[2], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(u7)\n",
    "    c7 = layers.Conv2D(filters[2], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(c7)\n",
    "\n",
    "    u8 = layers.Conv2DTranspose(filters[1], (2, 2), strides=(2, 2), padding=padding)(c7)\n",
    "    u8 = layers.concatenate([u8, c2])\n",
    "    c8 = layers.Conv2D(filters[1], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(u8)\n",
    "    c8 = layers.Conv2D(filters[1], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(c8)\n",
    "\n",
    "    u9 = layers.Conv2DTranspose(filters[0], (2, 2), strides=(2, 2), padding=padding)(c8)\n",
    "    u9 = layers.concatenate([u9, c1])\n",
    "    c9 = layers.Conv2D(filters[0], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(u9)\n",
    "    c9 = layers.Conv2D(filters[0], kernel_size, activation=activation, padding=padding, kernel_initializer=initializer)(c9)\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f66df499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def weightedBinaryCrossEntropy(y_test, y_pred, weights=[2.0, 1.0]):\n",
    "\n",
    "    # Debugging\n",
    "    print('**** Calculating Weighted Binary Cross Entroy ****')\n",
    "    print('* ytest:', type(y_test), y_test)\n",
    "    print('* ypred:', type(y_pred), y_pred)\n",
    "\n",
    "    print(len)\n",
    "\n",
    "    bce = np.zeros((y_test.shape))\n",
    "\n",
    "\n",
    "    # Debugging\n",
    "    print('**** Calculating Weighted Binary Cross Entroy ****')\n",
    "    # print('* ytest:', type(y_test), y_test)\n",
    "    # print('* ypred:', type(y_pred), y_pred)\n",
    "\n",
    "    print(y_test)\n",
    "\n",
    "\n",
    "    bce = np.zeros((y_test.shape))\n",
    "\n",
    "    for image in range(len(y_test)): # For image in batch\n",
    "\n",
    "        print(image)\n",
    "\n",
    "        for channel in range(len(image)): # For channel in image\n",
    "\n",
    "            for row in range(len(channel)): # For row in channel\n",
    "\n",
    "                for entry in range(len(row)): # For entry in each row\n",
    "\n",
    "                    print(y_pred[image][channel[row[entry]]])\n",
    "\n",
    "\n",
    "                    \n",
    "    return bce\n",
    "\n",
    "\n",
    "    # bce = weights * y_test  * tf.math.log(y_pred * K.epsilon)\n",
    "    # bce += weights[0] * (1 -y_test)  * tf.math.log(1 - y_pred * K.epsilon)\n",
    "\n",
    "    # print('* calcuated WBCE:', bce)\n",
    "    # return 1.\n",
    "    # weights = (y_test * 59.) + 1.\n",
    "    # bce = keras.loss.binary_crossentropy(y_test, y_pred)\n",
    "    # weighzed_bce = K.mean(bce * weights)\n",
    "    # return weighted_bce\n",
    "\n",
    "\n",
    "# **** Calculating Weighted Binary Cross Entroy ****\n",
    "# * ytest: <class 'tensorflow.python.framework.ops.SymbolicTensor'> Tensor(\"data_1:0\", shape=(4, 512, 512, 1), dtype=float32)\n",
    "# * ypred: <class 'tensorflow.python.framework.ops.SymbolicTensor'> Tensor(\"functional_3_1/conv2d_75_1/Sigmoid:0\", shape=(4, 512, 512, 1), dtype=float32)\n",
    "# * calcuated WBCE: Tensor(\"compile_loss/weighted_binary_cross_entropy/mul:0\", shape=(4, 512, 512, 2), dtype=float32)\n",
    "\n",
    "shape = (4, 512, 512, 1)\n",
    "\n",
    "test_array = np.zeros(shape)\n",
    "\n",
    "# test_bce = weightedBinaryCrossEntropy(test_array, test_array)\n",
    "# test_bce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8beae7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the model for training\n",
    "#############################################\n",
    "\n",
    "# Define hyperparameters\n",
    "hyperparameters = {\n",
    "    'input_shape': (512, 512, 3),\n",
    "    'filters': [32, 64, 128, 256, 512],\n",
    "    'kernel_size': (3, 3),\n",
    "    'activation': 'relu',\n",
    "    'padding': 'same',\n",
    "    'initializer': he_uniform(),\n",
    "    'optimizer': 'adam',\n",
    "    'loss': weightedBinaryCrossEntropy,\n",
    "    # 'loss': 'binary_crossentropy',\n",
    "    'metrics': ['accuracy'],\n",
    "    'epochs': 1,\n",
    "    'batch_size': 4,\n",
    "    'validation_split': 0.2,\n",
    "    'early_stopping_patience': 10\n",
    "}\n",
    "\n",
    "# Create and compile the model using hyperparameters\n",
    "model = unet_model(\n",
    "    input_shape=hyperparameters['input_shape'],\n",
    "    filters=hyperparameters['filters'],\n",
    "    kernel_size=hyperparameters['kernel_size'],\n",
    "    activation=hyperparameters['activation'],\n",
    "    padding=hyperparameters['padding'],\n",
    "    initializer=hyperparameters['initializer']\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=hyperparameters['optimizer'],\n",
    "    loss=hyperparameters['loss'],\n",
    "    metrics=hyperparameters['metrics']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c1e6c296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images:  (120, 512, 512, 3)\n",
      "Training masks:  (120, 512, 512, 1)\n",
      "Validation images:  (30, 512, 512, 3)\n",
      "Validation masks:  (30, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for training\n",
    "#############################################\n",
    "\n",
    "# Define the test size\n",
    "image_parameters = {\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "# This ensures that the data is in the correct format for train_test_split and model.fit.\n",
    "train_images = np.array(images)\n",
    "train_masks = np.array(masks)\n",
    "\n",
    "\n",
    "\n",
    "# Ensure the input data has the correct shape\n",
    "if train_images.ndim == 3: # If images are grayscale and have shape (num_samples, height, width)\n",
    "    train_images = np.expand_dims(train_images, axis=-1) # Add channel dimension\n",
    "if train_masks.ndim == 3: # If masks are grayscale and have shape (num_samples, height, width)\n",
    "    train_masks = np.expand_dims(train_masks, axis=-1) # Add channel dimension\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_images, val_images, train_masks, val_masks = train_test_split(train_images, train_masks, test_size=image_parameters['test_size'], random_state=image_parameters['random_state'])\n",
    "\n",
    "# Duplicate channels for the grayscale images since the model expects 3 channels\n",
    "train_images = np.repeat(train_images, 3, axis=-1)\n",
    "val_images = np.repeat(val_images, 3, axis=-1)\n",
    "\n",
    "# Use ImageDataGenerator to load data in batches\n",
    "train_datagen = ImageDataGenerator()\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow(train_images, train_masks, batch_size=hyperparameters['batch_size'])\n",
    "val_generator = val_datagen.flow(val_images, val_masks, batch_size=hyperparameters['batch_size'])\n",
    "\n",
    "# Show distribution of training and validation sets\n",
    "print('Training images: ', train_images.shape)\n",
    "print('Training masks: ', train_masks.shape)\n",
    "print('Validation images: ', val_images.shape)\n",
    "print('Validation masks: ', val_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "851767c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Calculating Weighted Binary Cross Entroy ****\n",
      "* ytest: <class 'tensorflow.python.framework.ops.Tensor'> Tensor(\"IteratorGetNext:1\", shape=(4, 512, 512, 1), dtype=float32)\n",
      "* ypred: <class 'tensorflow.python.framework.ops.Tensor'> Tensor(\"model_12/conv2d_246/Sigmoid:0\", shape=(4, 512, 512, 1), dtype=float32)\n",
      "<built-in function len>\n",
      "**** Calculating Weighted Binary Cross Entroy ****\n",
      "Tensor(\"IteratorGetNext:1\", shape=(4, 512, 512, 1), dtype=float32)\n",
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\shoulau\\Documents\\GitHub\\AstrID\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\shoulau\\AppData\\Local\\Temp\\ipykernel_27360\\2998653942.py\", line 29, in weightedBinaryCrossEntropy  *\n        for channel in range(len(image)): # For channel in image\n\n    TypeError: object of type 'int' has no len()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 13\u001b[0m\n\u001b[0;32m      5\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[0;32m      6\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# or another metric like 'val_accuracy'\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     patience\u001b[38;5;241m=\u001b[39mhyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearly_stopping_patience\u001b[39m\u001b[38;5;124m'\u001b[39m],         \u001b[38;5;66;03m# Number of epochs with no improvement before stopping\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Restores the model to the best state after stopping\u001b[39;00m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_masks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shoulau\\Documents\\GitHub\\AstrID\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file3e7h7bgb.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileeczmc6ql.py:63\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__weightedBinaryCrossEntropy\u001b[1;34m(y_test, y_pred, weights)\u001b[0m\n\u001b[0;32m     61\u001b[0m channel \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     62\u001b[0m image \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 63\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterate_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileeczmc6ql.py:58\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__weightedBinaryCrossEntropy.<locals>.loop_body_3\u001b[1;34m(itr_3)\u001b[0m\n\u001b[0;32m     56\u001b[0m         ag__\u001b[38;5;241m.\u001b[39mfor_stmt(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mrange\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mlen\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(row),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), \u001b[38;5;28;01mNone\u001b[39;00m, loop_body, get_state, set_state, (), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterate_names\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentry\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     57\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mfor_stmt(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mrange\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mlen\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(channel),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), \u001b[38;5;28;01mNone\u001b[39;00m, loop_body_1, get_state_1, set_state_1, (), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterate_names\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m---> 58\u001b[0m ag__\u001b[38;5;241m.\u001b[39mfor_stmt(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mrange\u001b[39m), (\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), \u001b[38;5;28;01mNone\u001b[39;00m, loop_body_2, get_state_2, set_state_2, (), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterate_names\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannel\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\shoulau\\Documents\\GitHub\\AstrID\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\shoulau\\AppData\\Local\\Temp\\ipykernel_27360\\2998653942.py\", line 29, in weightedBinaryCrossEntropy  *\n        for channel in range(len(image)): # For channel in image\n\n    TypeError: object of type 'int' has no len()\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "#############################################\n",
    "\n",
    "# Implement Early stopping to cut useless epochs\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # or another metric like 'val_accuracy'\n",
    "    patience=hyperparameters['early_stopping_patience'],         # Number of epochs with no improvement before stopping\n",
    "    restore_best_weights=True  # Restores the model to the best state after stopping\n",
    ")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_masks, \n",
    "                    validation_data=(val_images, val_masks), \n",
    "                    epochs=hyperparameters['epochs'], \n",
    "                    batch_size=hyperparameters['batch_size'],\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9056adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  3.1238722801208496\n",
      "Validation loss:  2.555122137069702\n",
      "Training accuracy:  0.9907637238502502\n",
      "Validation accuracy:  0.9925941228866577\n"
     ]
    }
   ],
   "source": [
    "# Show training loss and validation loss\n",
    "print('Training loss: ', history.history['loss'][-1])\n",
    "print('Validation loss: ', history.history['val_loss'][-1])\n",
    "\n",
    "# Show training accuracy and validation accuracy\n",
    "print('Training accuracy: ', history.history['accuracy'][-1])\n",
    "print('Validation accuracy: ', history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b431a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(24, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1af23663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('150unet_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322ff4ef-a8b3-4b9f-af7b-cdf0c5437e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Set a larger figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(history.history['loss'], color='blue', linestyle='-', linewidth=2, label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', linestyle='--', linewidth=2, label='Validation Loss')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Training and Validation Loss Over Epochs', fontsize=16)\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "# Add a grid for better readability\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Add legend to differentiate between training and validation loss\n",
    "plt.legend(loc='best', fontsize=12)\n",
    "\n",
    "# Set limits for better visualization\n",
    "plt.xlim(0, len(history.history['loss']) - 1)  # From epoch 0 to the last epoch\n",
    "plt.ylim(min(history.history['loss']) * 0.95, max(history.history['val_loss']) * 1.05)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae06b48f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639116f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
