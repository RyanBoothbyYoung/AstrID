{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba16ade-d8d8-427b-8d11-a6b51c33e639",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3b4860f-849d-43af-842a-b555779b742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5e9ee6-5be5-4528-98fc-4bab7acf2812",
   "metadata": {},
   "source": [
    "### Architecture Overview \n",
    "The goal of our network will be to learn which features to extract from our images and then determine which features belong to which class. To start we will attempt to determine which features are stars. As we progress through this process we may attempt to classify more objects in our images.\n",
    "\n",
    "To do this we will use the CNN base architecture to start\n",
    "CNN architecture consists of two main parts \n",
    "* a Convolutional Base\n",
    "* a Dense Head\n",
    "\n",
    "In a CNN the convolutional base is used to extract the required features from images, and the head is used to determine the correct class for those features. \n",
    "\n",
    "Modern classifiers utilize transfer learning, our CNN will attempt to follow this common framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2066cbaf-bf26-4e51-8067-c480ab04475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_base = keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape = (300,300,3), #defaults to (224, 224, 3) 224x224 colour. Update with actual dimensions\n",
    "    classes = 2, #placeholder until classifiers can be set\n",
    "    classifier_activation = 'sigmoid', #sigmoid for binary classification, softmax if more are added\n",
    ")\n",
    "\n",
    "for layer in old_base.layers:\n",
    "    layer.trainable = False #freeze base layers\n",
    "\n",
    "AstrID = models.Sequential([\n",
    "    old_base,\n",
    "    layers.Dense(300, activation ='relu'),\n",
    "    layers.Dropout(rate = 0.3),\n",
    "    layers.Dense(2, activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "AstrID.compile(\n",
    "    optimizer='adam',\n",
    "    loss = 'BinaryCrossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46c0a648-b8f3-4726-8ecb-c9c798e460e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "## Used this code to confirm the channels present in the .fits files \n",
    "# While they appear as greyscale they are 3 channel RGB images. \n",
    "# If they were not 3 channel RGB images and instead 1 channel greyscale \n",
    "# the current recommended method is to increase the channel size and then duplicate the image into each channel\n",
    "\n",
    "\n",
    "img = image.load_img('../space_test/images/Crab_Nebula/Crab_Nebula.fits')\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "print(\"Image shape:\", img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a088add1-682a-498d-bd9d-fdaca5ca7428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
